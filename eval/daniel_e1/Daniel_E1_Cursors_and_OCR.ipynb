{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_frame(cap, index):\n",
    "    ''' Display a frame from a video capture stream. '''\n",
    "    frame = get_frame(cap, index)\n",
    "    display_image(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    ''' Show an image in a matplotlib figure. '''\n",
    "    # If colored, swap color order to RGB\n",
    "    if len(image.shape) > 2:\n",
    "        image = image[:,:,[2,1,0]]\n",
    "        imshow(image)\n",
    "    else:\n",
    "        imshow(image, cmap=cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_rows(images, ncols=4):\n",
    "    matrix = []\n",
    "    for i in xrange(0, len(images), ncols):\n",
    "        matrix.append(images[i:i+ncols])\n",
    "    image_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_matrix(images, imgsize=(8, 5)):\n",
    "    ''' Show matrix of images of variable size. '''\n",
    "    if len(images) == 0 or len(images[0]) == 0:\n",
    "        return\n",
    "    rows = len(images)\n",
    "    cols = len(images[0])\n",
    "    w, h = imgsize\n",
    "    figure(figsize=(w * cols, h * rows))\n",
    "    for r, row in enumerate(images):\n",
    "        for c, img in enumerate(row):\n",
    "            spn = r * cols + c + 1\n",
    "            subplot(rows, cols, spn)\n",
    "            display_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_rectangle(image, rect):\n",
    "    ''' Draw a rectangle on an image. '''\n",
    "    l, t, w, h = rect\n",
    "    cv2.rectangle(image, \n",
    "        (l, t),\n",
    "        (l + w, t + h), \n",
    "        (0, 255, 0), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Stream Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' Helpers for fetching specific frames. '''\n",
    "get_findex = lambda cap : int(cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES))\n",
    "set_findex = lambda cap, f : cap.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_frame(cap, index):\n",
    "    ''' Modified from code on SO question, \"How to process images of a video, frame \n",
    "        by frame in video streaming using Opencv python \"'''\n",
    "    \n",
    "    set_findex(cap, index)    \n",
    "    logging.debug(\"Fetching frame %d\", index)\n",
    "\n",
    "    while True:\n",
    "        flag, frame = cap.read()    \n",
    "        if flag:\n",
    "            logging.debug(\"Got frame %d\", index)\n",
    "            return frame\n",
    "            break\n",
    "        else:\n",
    "            logging.debug(\"Frame %d not ready, trying again\", findex)\n",
    "            # The frame number increments after a read attempt.\n",
    "            # Furthermore, to try to read frame i, we set frame number to i + 1.\n",
    "            # I don't know why, but this is just how the API works.\n",
    "            index = get_findex(cap)\n",
    "            set_findex(cap, index)\n",
    "            cv2.waitKey(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load video streams (make sure you're in the right directory, and check for possible warnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_paths = [\n",
    "    'videos/1-vXcC533_IcQ-Android_-_Eclipse_-_02_-_Creating_a_Custom_Splash_Screen_-_Tutorial.mp4',\n",
    "    'videos/2--MBS2YvUY2M-Android_Facebook_Login_integration_with_Eclipse..mp4',\n",
    "    'videos/3-p9KRJoX13vo-Android_Development_Tutorial_-_How_To_Make_an_App_and_Run_It_In_The_Emulator.mp4',\n",
    "    'videos/4-o1vRJ07KDZ0-Android_tutorial_make_android_calculator_app_video_how_to_create_a_calculator_in_android_shashank_ku.mp4',\n",
    "    'videos/5-ok8mZW_BDG4-Eclipse_Java_Hello_World_Introduction_Tutorial.mp4'\n",
    "]\n",
    "streams = [cv2.VideoCapture(p) for p in video_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frame rate corrections for where QuickTime's perceived FPS\n",
    "# is different than what OpenCV reads in\n",
    "# Also, we found extracted rectangle positions from smaller images than the\n",
    "# actual video feed, so we have to scale them back up\n",
    "fcorr = {\n",
    "    1: 29.41176470588235 / 29.970030,\n",
    "}\n",
    "scorr = {\n",
    "    1: (852.0/639, 480.0/360),\n",
    "    2: (854.0/641, 460.0/345),\n",
    "    3: (854.0/588, 480.0/330),\n",
    "    4: (854.0/608, 464.0/330),\n",
    "    5: (768.0/576, 480.0/360),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('rectangles.csv') as datafile:\n",
    "    data = csv.DictReader(datafile, )\n",
    "    records = []\n",
    "    for r in data:\n",
    "        records.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = []\n",
    "\n",
    "for r in records:\n",
    "\n",
    "    # Get video and frame index\n",
    "    vindex = int(r['Vindex'])\n",
    "    frame_index = int(int(r['Frame']) * fcorr.get(vindex, 1))\n",
    "\n",
    "    # Load up rectangle data\n",
    "    xcorr, ycorr = scorr.get(vindex, 1)    \n",
    "    x, w = [int(int(d) * xcorr) for d in (r['x'], r['w'])]\n",
    "    y, h = [int(int(d) * ycorr) for d in (r['y'], r['h'])]\n",
    "    \n",
    "    # Store as more readable event dictionary\n",
    "    event = {\n",
    "        'stream_index': vindex - 1,\n",
    "        'frame_index': frame_index,\n",
    "        'rect': (x, y, w, h),\n",
    "    }\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the frames and menu regions from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "for e in events: \n",
    "    f = get_frame(streams[e['stream_index']], e['frame_index'])\n",
    "    x,y,w,h = e['rect']\n",
    "    cv2.rectangle(f, (x,y), (x+w,y+h), (0,128,0), 10)\n",
    "    frames.append(f)\n",
    "#image_rows(frames, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Menus from Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Processing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recent_diff(cap, fend, frames_before=10):\n",
    "    '''\n",
    "    Get a smooth difference in pixels leading up to a frame.\n",
    "    Adds up the differences from a sequence of earlier frames \n",
    "    and 'normalizing' based on the largest difference\n",
    "    found.  Cancels out some noise from a single image difference.\n",
    "    '''\n",
    "    frame_shape = get_frame(cap, fend).shape\n",
    "    diff = np.zeros(frame_shape, dtype='uint32')\n",
    "    for f in range(fend - frames_before, fend + 1):\n",
    "        f1 = get_frame(cap, f)\n",
    "        f2 = get_frame(cap, f + 1)\n",
    "        diff += (f2 - f1)\n",
    "    \n",
    "    diff_norm = diff * (255.0 / np.max(diff))\n",
    "    diff_norm = diff_norm.astype('uint8')\n",
    "    return diff_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blur_image(image, ksize=(15,15), sigma=7):\n",
    "    return cv2.GaussianBlur(image, ksize, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(image, threshold=30):\n",
    "    _, binarized = cv2.threshold(image.copy(), threshold, 255, cv2.THRESH_BINARY)\n",
    "    scaled = binarized\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contours(image, minarea=5000):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = filter(lambda c: cv2.contourArea(c) > 5000, contours)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_rgb = lambda img: cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "to_grey = lambda img: cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract differences leading up to each of the frames, show with the expected bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "diff_images = []\n",
    "for e in events:\n",
    "    stream = streams[e['stream_index']]\n",
    "    diff = recent_diff(stream, e['frame_index'])\n",
    "    x,y,w,h = e['rect']\n",
    "    diff_image = diff.copy()\n",
    "    cv2.rectangle(diff_image, (x,y), (x+w,y+h), (0,128,0), 10)\n",
    "    diffs.append(diff)\n",
    "    diff_images.append(diff_image)\n",
    "#image_rows(diff_images, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the bounding rectangles of regions where a difference was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "blurred_images = []\n",
    "binarized_images = []\n",
    "image_contours = []\n",
    "image_rects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, e in enumerate(events):\n",
    "    \n",
    "    stream_index = e['stream_index']\n",
    "    frame_index = e['frame_index']\n",
    "    stream = streams[stream_index]\n",
    "    image = get_frame(stream, frame_index)\n",
    "    \n",
    "    # Get contours for image\n",
    "    blurred = blur_image(to_grey(diffs[i]))\n",
    "    binarized = binarize(blurred)\n",
    "    contours = get_contours(binarized)\n",
    "    rects = [cv2.boundingRect(c) for c in contours]\n",
    "    \n",
    "    images.append(image)\n",
    "    blurred_images.append(blurred)\n",
    "    binarized_images.append(binarized)\n",
    "    image_contours.append(contours)\n",
    "    image_rects.append(rects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show decision process for selecting menu regions from frame differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = []\n",
    "\n",
    "for i, e in enumerate(events):\n",
    "    \n",
    "    # Draw contours on top of differences\n",
    "    diff = diffs[i]\n",
    "    contour_image = diff.copy()\n",
    "    cv2.drawContours(contour_image, image_contours[i], -1, (255,255,0), 5)\n",
    "    \n",
    "    # Draw rectangles on top of differences\n",
    "    rect_image = diff.copy()\n",
    "    for r in image_rects[i]:\n",
    "        x, y, w, h = r\n",
    "        cv2.rectangle(rect_image, (x, y), (x + w, y + h), (0,0,255), 5)\n",
    "        \n",
    "    # Put all into a matrix for us to display\n",
    "    matrix.append([\n",
    "        images[i],\n",
    "        diffs[i],\n",
    "        to_rgb(blurred_images[i]),\n",
    "        to_rgb(binarized_images[i] * 255),\n",
    "        contour_image,\n",
    "        rect_image,\n",
    "    ])\n",
    "\n",
    "#image_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the regions that we extracted from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for i, e in enumerate(events):\n",
    "    image = images[i].copy()\n",
    "    for r in image_rects[i]:\n",
    "        x, y, w, h = r\n",
    "        image_with_region = image.copy()\n",
    "        cv2.rectangle(image_with_region, (x, y), (x + w, y + h), (0,0,255), 5)\n",
    "        matrix.append([\n",
    "            image,\n",
    "            image_with_region,\n",
    "            image[y:y+h,x:x+w,:]\n",
    "        ])\n",
    "#image_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou(expected, observed):\n",
    "    \n",
    "    ex, ey, ew, eh = expected\n",
    "    ox, oy, ow, oh = observed\n",
    "    \n",
    "    il = max(ex, ox)\n",
    "    ir = min(ex + ew, ox + ow)\n",
    "    it = max(ey, oy)\n",
    "    ib = min(ey + eh, oy + oh)\n",
    "    ir = il if ir < il else ir\n",
    "    ib = it if ib < it else ib\n",
    "    intersection_area = (ir - il) * (ib - it)\n",
    "    \n",
    "    union_area = ew * eh + ow * oh - intersection_area\n",
    "    return intersection_area / float(union_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ious = []\n",
    "matches = []\n",
    "\n",
    "for i, e in enumerate(events):\n",
    "    best_iou = 0\n",
    "    for r in image_rects[i]:\n",
    "        score = iou(e['rect'], r)\n",
    "        best_iou = score if score > best_iou else best_iou\n",
    "    matches.append(True if best_iou > 0 else False)\n",
    "    ious.append(best_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========OVERALL RESULTS============\n",
      "\n",
      "Found matching windows for 29/33 test frames (88%)\n",
      "Avg IoU for matches: 70%\n",
      "Avg false positives per image: 0.060606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\"\n",
    "print \"===========OVERALL RESULTS============\"\n",
    "print \"\"\n",
    "\n",
    "correct = sum(matches)\n",
    "total = len(matches)\n",
    "print \"Found matching windows for %d/%d test frames (%2.f%%)\" % (correct, total, 100*float(correct)/total)\n",
    "\n",
    "valid_ious = [i*100 for i in ious if i > 0]\n",
    "print \"Avg IoU for matches: %2.f%%\" % (average(valid_ious))\n",
    "\n",
    "rect_counts = [len(r) for r in image_rects]\n",
    "false_positives = sum(map(lambda x: max(0, x-1), rect_counts))\n",
    "print \"Avg false positives per image: %f\" % (float(false_positives) / len(images))\n",
    "\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1029aeed0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEZCAYAAAB1mUk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAFq5JREFUeJzt3XmcZWV95/HPl33fogNNBBpURiHCyLigmNAijh0kaCbI\n",
       "MooIickkGFAjI23U6WSMjMMwymAkYxAEDBCVhNAzDtIuHSEaUNIIAoqYaRaxu1mbbZTtlz/OKep2\n",
       "Ucvtqrr3Vvf9vF+vevU92/M891TX+Z7nOfecm6pCkjTcNhp0AyRJg2cYSJIMA0mSYSBJwjCQJGEY\n",
       "SJIwDLQOkpyT5MOzVNbuSR5JknZ6WZLfno2y2/K+kuS42SpvHer9WJJ7k9zT77qnK8m7klw96HZo\n",
       "sAwDAZBkRZLHkzyc5MEk/5Dk90YO1gBV9ftV9bEuyzpksnWq6s6q2rZGb3Sp9mc6bV+c5KIx5R9W\n",
       "VRdNtE0vJNkdeD/wkqradZzlC5Lc1WVZn0/yX8bMm5/kmST+3WrW+Z9KIwo4vKq2A3YH/ivwQeBz\n",
       "0ywrEy1Mssm0Wjj37Q7cX1X3z0JZ0w5HaToMAz1HVT1SVUuAo4Hjk+wDa5+tJnlekv/d9iLuT/Kt\n",
       "NC6iOSguaYeBPtBxRntikjuAryXZY5yz3BcluTbJmiSXJ9mxres5Z9Rt7+MNSRYCi4Cj2/qWt8uf\n",
       "HXZq2/XhdptVSS5Isl27bKRt70xyRzvE86GJ9k2S7ZNcmGR1W94ft+UfClwF7Nq247yp9nOSXZNc\n",
       "0e6/Hyf5nbGrTFVGR1nnJDljzLy/S/Le9vVpSW5ve343J3nrBOU8p/cxdgiv/T3ekuSBJFe2PaKR\n",
       "ZZ9s9/GaJDcm2bfb96DBMgw0oar6LnA38Ksjsxg9W/0j4C7gecC/AhZV4zjgTppexrZV9d87ivw1\n",
       "4CXAm3jugS7AO4ETgHnAU8D/nKx5TRPrSuDjwKVtfS8fp60nAMcDC4C9gG2AT48p7yBgb+ANwEeT\n",
       "vGSCes8GtgX2BA4eaXNVfQ34deCeth0nTtL2EZfS7Kt5wJHAx5O8vovtxnMxTXgD0AbpG9s6AG4H\n",
       "Xtf2/P4E+EKSnbss+9l9meQtNOH7mzS/+6uBS9plb6L5v/LiqtoeeBswG70k9YFhoKncA+w0zvwn\n",
       "aA5i86vq6ar6hy7KWlxV/7+qfjHOsgIurKpbqupx4CPAUZ3XLCYRJj+LfjtwZlWtqKrHaA5mx4zp\n",
       "lfxJVf2iqm4Evg/s/5xKko1pDriLquqxqroDOBMYuVC9LmfyuwGvBT5YVU9U1feBc2nCZTquASrJ\n",
       "SHAfCXy7qlYCVNWXO15/Efgx8Opp1PMfgdOr6kdV9QxwOvBv2t7BEzRB+dIkG7XrrJzm+1GfGQaa\n",
       "yguABzqmRw54Z9CcbV6V5CdJPthFWVNdPO1cfiewKc3Z50zNA+4YU/YmQOeZcedB63Fg63HKeV7b\n",
       "prFl/fI02rQr8EAbTuOV9VRbV6dNgWfag/Ba2gvxlwLHtrP+A/BXI8vbYbDl7bDeg8CvAL80jXbv\n",
       "AZzVUc7Imf+uVfVNmh7XnwOrkvyvJNtOow4NgGGgCSV5Jc1B65qxy6rq0ar6QFW9EDgCeH/HEMdE\n",
       "Fz6nuiC6+5jXTwL3AY8BW3W0a2Pg+etQ7j3A/DFlPwWsmmK7se5r2zS2rLvXsZyRNu2UZJsJyrpz\n",
       "TD3QDE1NFqiXAEcm2QN4FXAZQDv9WeAkYKeq2hH4AeP3ZEbCaauOebt0vL4T+N2q2rHjZ+uq+keA\n",
       "qjq7ql4B7EMz7HbqJO3VHGIYqNPIZ/63S3I4zcHloqq6uXN5u87hSV7UDuM8DDwNjJyxrgJeOI26\n",
       "35HkpUm2Av4U+FJ7xnsbsEWSw5JsCnwY2Lxj25XA/EmGlC4B3tdeHN2G0WsMzznDHtOetVTV08AX\n",
       "gT9Lsk17kH0f8IV1e6tQVXcB3wZOT7J5kv2AEzvKugx4c5I3Jtk4ya407/uSScq8gSawzgWurKqH\n",
       "20Vb0wTmfcBGSU6g6RmMV8a9wE+B49p6T2Tt3+VfAB/K6IcKtk/ytvb1K5K8uv0dPQ78nOb/hdYD\n",
       "hoE6LUnyMM3Z3yKa8fATOpZ3XpR9EbAUeITmoPbnVfX37bLTgQ+3Qwnv79h2rBrz+kLg88DPgM2A\n",
       "kwGqag3wBzQHubuBR1n7DPlL7b/3J/neOPWcB1wEfAv4Z5oD1R9O0I7J5tFu91hbztU0QzHnd7Hd\n",
       "eMuPpTn7vwf4G+CjVfUNgKq6pV1+Os1QzLeB79Bc/J3MxcAh7b90lHVmu/1KmiDo7O2N/Rjru2nO\n",
       "6O+jOcN/9npQVV0OfAK4NMka4CaaDwQAbEfTA3kAWNFuv9YnnDR3pVdfbtN+tO7NwOqqelk77wzg\n",
       "cJoLTT+h+RTGmp40QJLUtV72DM4HFo6ZdxWwb1XtT9P1X9TD+iVJXepZGFTV1cCDY+Yt7RinvZbm\n",
       "kyqSpAEb5DWDE4GvDLB+SVJrIGGQ5I+BJ6rq4ilXliT1XN8fGJbkXcBhNLf9T7SOD+iSpGmoqq7v\n",
       "hO/U1zBI81CxU4GDq+rnk6073Te0oUmyuKoWD7odc4H7YpT7YpT7YtRMTqR7NkyU5BKaz0b/6yR3\n",
       "tTevnE3zkLCl7a3xn+lV/ZKk7vWsZ1BVx44ze8rH+kqS+s87kOe+ZYNuwByybNANmEOWDboBc8iy\n",
       "QTdgQ9CzO5BnIkl5zUCS1s1Mjp32DCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEg\n",
       "ScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnD\n",
       "QJKEYSBJoodhkOS8JKuS3NQxb6ckS5PcluSqJDv0qn5JUvd62TM4H1g4Zt5pwNKq2hv4ejstSRqw\n",
       "noVBVV0NPDhm9hHABe3rC4C39qp+SVL3+n3NYOeqWtW+XgXs3Of6JUnjGNgF5KoqoAZVvyRp1CZ9\n",
       "rm9Vkl2qamWSecDqiVZMsrhjcllVLet14yQNlyR9PyGtqsxWWUkWAAtmpazmBL03kswHllTVy9rp\n",
       "/wbcX1WfSHIasENVPecicpKazR0mSeNpwqCfeZBZDYPnlD6DY2fPwiDJJcDBwPNorg98FPg74IvA\n",
       "7sAK4KiqemicbQ0DST1nGHRs28uewXQZBpL6wTAY5R3IkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEk\n",
       "CcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwD\n",
       "SRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQGFAZJFiW5OclNSS5Osvkg2iFJavQ9DJLMB94N\n",
       "HFBVLwM2Bo7pdzskSaM2GUCdDwNPAlsleRrYCvjpANohSWr1vWdQVQ8AZwJ3AvcAD1XV1/rdDknS\n",
       "qL73DJK8EHgvMB9YA3wpydur6q/GrLe4Y3JZVS3rVxslaX2QZAGwYFbKqqrZKKf7CpOjgTdW1e+0\n",
       "08cBB1bVSR3rVFWlrw2TNHSSFPTzGBh6eWybybFzEJ8m+iFwYJItkwQ4FLhlAO2QJLUGcc3g+8CF\n",
       "wPeAG9vZn+13OyRJo/o+TNQNh4kk9YPDRKO8A1mSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiS\n",
       "MAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEl2EQZLXjTPvoN40R5I0\n",
       "CN30DM4eZ96nZ7shkqTB2WSiBUleA7wWeH6S9wNpF22Lw0uStEGZMAyAzWgO/Bu3/454GDiyl42S\n",
       "JPVXqmryFZL5VbWiP815ts6qqky9piRNX5KCyY+Bs1wjvTy2zeTYOVnPYMTmSf4SmN+xflXVIdOp\n",
       "UJI093TTM7gROAf4J+DpdnZV1fU9a5Q9A0l9YM9gVDc9gyer6pzpFC5JWj9086mgJUlOSjIvyU4j\n",
       "Pz1vmSSpb7oZJlrBOP2oqtpz2pUmOwDnAvu2ZZ9YVf/YsdxhIkk95zDRqCmHiapq/nQKnsJZwFeq\n",
       "6sgkmwBb96AOSVKXuukZHM/4PYMLp1Vhsj2wvKr2mmQdewaSes6ewahuLiC/ktG9tSVwCM0ni6YV\n",
       "BsCewL1Jzgf2B64HTqmqx6dZniRphroZJnpP53Q73v/XM6zzAOA9VfXdJJ8CTgM+OqaexR2Ty6pq\n",
       "2QzqlKQNTpIFwIJZKWuqYaJxKt8M+EFV7T2tCpNdgO+MXIBun4p6WlUd3rGOw0SSes5holFT9gyS\n",
       "LOmY3AjYB/jidCoDqKqVSe5KsndV3QYcCtw83fIkSTPXzQXkBe3LAp4C7qyqu2ZUabI/zUdLNwN+\n",
       "ApxQVWs6ltszkNRz9gw6tu1mmKgd2hm5kHxdVa2eTmVdN8owkNQHhsGobr7p7CjgWuBtwFHAdUne\n",
       "Np3KJElzU7cPqjt0pDeQ5PnA16tqv541yp6BpD6wZzCqm2cTBbi3Y/p+Rr/1TJK0AejmprMrga8m\n",
       "uZgmBI4G/m9PWyVJ6qsJh4mSvBjYuaquSfJbwEHtooeAi6vq9p41ymEiSX3gMFHHtpOEwf8BFlXV\n",
       "jWPm7wf8WVX9xnQq7KpRhoGkPjAMRk12zWDnsUEA0M6b9uOrJUlzz2RhsMMky7aY7YZIkgZnsjD4\n",
       "XpLfHTszybtpnjQqSdpATHbNYBfgb4EnGD34/1tgc+A3q+pnPWuU1wwk9YHXDDq2neymsyQBXg/8\n",
       "Cs0eu7mqvjGtVq5LowwDSX1gGHRsu66PsO4Hw0BSPxgGo7q5A1mStIEzDCRJXT2OQtIQa4ZS+sth\n",
       "4v4zDCR1ob/j6uo/h4kkSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhI\n",
       "khhgGCTZOMnyJEsG1QZJUmOQPYNTgFvo7+MQJUnjGEgYJHkBcBhwLj6vVpIGblA9g08CpwLPDKh+\n",
       "SVKHvn+5TZLDgdVVtTzJgknWW9wxuayqlvW4adJ6YxDfPtZPG/r7my3tMXTBrJRV1d99nuTjwHHA\n",
       "U8AWwHbAZVX1zo51yq+9kybWHCz79bcb+v9NZxvue+vlsW0mx86+h8FalScHAx+oqt8YM98wkCZh\n",
       "GKyPdTX1zdUwmAv3GdgdlKQBG2jPYCL2DKTJ2TNYH+tq6rNnIEmaswwDSZJhIEkyDCRJGAaSJAwD\n",
       "SRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQG8E1n65sk84Df63O1n6+qFX2uU9IQMwymNg92\n",
       "PA1O3rw/1f3FL2DVN4EV/alvwzWIr0700etaXxkGXfmln8PiPoXBFT+HVf2paij0+zn80vrJawaS\n",
       "JMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSQwgDJLsluSbSW5O8oMk\n",
       "J/e7DZKktQ3iqaVPAu+rqhuSbANcn2RpVd06gLZIkhhAz6CqVlbVDe3rR4FbgV373Q5J0qiBXjNI\n",
       "Mh94OXDtINshScNuYGHQDhF9GTil7SFIkgZkIN90lmRT4DLgC1V1+QTrLO6YXFZVy/rQNElabyRZ\n",
       "ACyYjbL6HgZJAnwOuKWqPjXRelW1uG+NkqT1UHuSvGxkOsl/nm5ZgxgmOgh4B/D6JMvbn4UDaIck\n",
       "qdX3nkFVXYM3u0nSnOJBWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKG\n",
       "gSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIk\n",
       "DANJEoaBJIkBhUGShUl+mOTHST44iDZIkkb1PQySbAx8GlgI7AMcm+Sl/W7H+iLJgkG3Ya5wX2h8\n",
       "ywbdgA3CIHoGrwJur6oVVfUkcCnwlgG0Y32xYNANmEMWDLoBmouWDboBG4RBhMEvA3d1TN/dzpMk\n",
       "DcgmA6izBlDnDN29JRyypj91/WiL/tQjSaNS1d9jc5IDgcVVtbCdXgQ8U1Wf6FhnPQwMSRq8qsp0\n",
       "thtEGGwC/Ah4A3APcB1wbFXd2teGSJKe1fdhoqp6Ksl7gK8CGwOfMwgkabD63jOQJM09c+4O5GG9\n",
       "IS3Jbkm+meTmJD9IcnI7f6ckS5PcluSqJDsMuq39kmTjJMuTLGmnh3JfJNkhyZeT3JrkliSvHuJ9\n",
       "saj9G7kpycVJNh+WfZHkvCSrktzUMW/C997uqx+3x9N/N1X5cyoMhvyGtCeB91XVvsCBwEntez8N\n",
       "WFpVewNfb6eHxSnALYx+Am1Y98VZwFeq6qXAfsAPGcJ9kWQ+8G7ggKp6Gc0w8zEMz744n+bY2Gnc\n",
       "955kH+BomuPoQuAzSSY93s+pMGCIb0irqpVVdUP7+lHgVpr7L44ALmhXuwB462Ba2F9JXgAcBpwL\n",
       "jHw6Yuj2RZLtgV+tqvOgueZWVWsYwn0BPExz0rRV+0GUrWg+hDIU+6KqrgYeHDN7ovf+FuCSqnqy\n",
       "qlYAt9McXyc018LAG9J49gzo5cC1wM5VtapdtArYeUDN6rdPAqcCz3TMG8Z9sSdwb5Lzk/xTkr9M\n",
       "sjVDuC+q6gHgTOBOmhB4qKqWMoT7osNE731XmuPniCmPpXMtDIb+anaSbYDLgFOq6pHOZdVc7d/g\n",
       "91GSw4HVVbWc0V7BWoZlX9B84u8A4DNVdQDwGGOGQYZlXyR5IfBeYD7NwW6bJO/oXGdY9sV4unjv\n",
       "k+6XuRYGPwV265jejbXTbYOWZFOaILioqi5vZ69Ksku7fB6welDt66PXAkck+X/AJcAhSS5iOPfF\n",
       "3cDdVfXddvrLNOGwcgj3xSuAb1fV/VX1FPA3wGsYzn0xYqK/ibHH0he08yY018Lge8CLk8xPshnN\n",
       "BZArBtymvkgS4HPALVX1qY5FVwDHt6+PBy4fu+2Gpqo+VFW7VdWeNBcIv1FVxzGc+2IlcFeSvdtZ\n",
       "hwI3A0sYsn1Bc+H8wCRbtn8vh9J8wGAY98WIif4mrgCOSbJZkj2BF9Pc4DuxqppTP8Cv09yhfDuw\n",
       "aNDt6eP7fh3N+PgNwPL2ZyGwE/A14DbgKmCHQbe1z/vlYOCK9vVQ7gtgf+C7wPdpzoa3H+J98Z9o\n",
       "wvAmmgummw7LvqDpJd8DPEFzbfWEyd478KH2OPpD4E1Tle9NZ5KkOTdMJEkaAMNAkmQYSJIMA0kS\n",
       "hoEkCcNAkoRhoCGU5NEpli8YeWx2x7zPJ/mtjum/TrJX+wjlK9tHKv9+x/LPJnl5x/TJSY6bzfch\n",
       "zSbDQMNoOjfXPPvclyQvArauqn8G3gR8i+bR0se1y/en+eKo5R3bnw/84UwaLfWSYaChlcYZ7Vn9\n",
       "jUmO6nLTYxh9TMoTwNbAZow+VO9PgY90blDNQwfvT7LvLDRdmnWGgYbZv6d51MN+NM+5OWPkoV9T\n",
       "OIjmOVoAS2meovkd4KwkRwDXV/NMobGuA35tpo2WemGTQTdAGqDXARdX80yW1Un+HnglsGaC9UeG\n",
       "l/YAfgZQVU8Db4dnnzp7JfCWJP+D5qmRF1bVyPWHe4C9evFGpJmyZ6BhVjz3+xIKuB/Yccz8nYD7\n",
       "OqbH+56FP6B5eNqBwEM0T939ozHb+DAwzUmGgYbZ1cDRSTZK8nyaIZzraJ70uGuSlwAk2YNmOOmG\n",
       "drs7gHmdBSXZEXhzVV1I83WMI9/QtmXHavOAFb15K9LMOEykYVQAVfW3SV5D82joAk6tqtUA7Tdo\n",
       "nZ9kC5rv3f3tGv3muWtovmjl+o4yPwJ8rH39VeAk4EbgnI51XgV8oCfvSJohH2EtraMkewFnV9Wb\n",
       "12Gb7YCvV9Ure9cyafocJpLWUXt/wSPtd/J2613AWb1pkTRz9gwkSfYMJEmGgSQJw0CShGEgScIw\n",
       "kCRhGEiSgH8Ba1l8W46qSYEAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10952f810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, _, _ = hist(valid_ious)\n",
    "ylim(0, 1.2*max(counts))\n",
    "xlim(0, 100)\n",
    "xlabel(\"IoU(%)\")\n",
    "ylabel(\"Count\")\n",
    "title(\"Distribution of IoU values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract-OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to get some OCR working. This will create several output images. Make sure you have tesseract installed (use \"brew install tesseract\"). I have version 3.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "for i in range(len(matrix)):\n",
    "    num = \"{0:02d}\".format(i)\n",
    "    cv2.imwrite('Images/image_' + num + '.png', matrix[i][0])\n",
    "    command = \"tesseract Images/image_\" + num + \".png Images/out_\" + num\n",
    "    subprocess.call(command.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results, um, leave a lot to be desired. Check out the out_i.txt files and compare that with the original image. But at least for the video with the captions, the OCR captures the captions themselves. Now let's try to see how it works with the exracted regions we developed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(matrix)):\n",
    "    num = \"{0:02d}\".format(i)\n",
    "    cv2.imwrite('Images/image_cropped' + num + '.png', matrix[i][2])\n",
    "    command = \"tesseract Images/image_cropped\" + num + \".png Images/out_cropped\" + num\n",
    "    subprocess.call(command.split())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Here was what Tesseract decided to say for the image_cropped00.txt one (see out_cropped00.txt):\n",
    "  \n",
    "  1 Eu-:.«....;.-:».us.Ea..«ww-ac.\n",
    "  2 \n",
    "  3 It ‘*5’-M\" ~q- um 94 ;.,.\n",
    "  4 W‘, T\n",
    "  5 \n",
    "  6 u... cm-w\n",
    "  7 \n",
    "  8 s.‘ cum\n",
    "  9 \n",
    " 10 loan: H\n",
    " 11 o; -4. n\n",
    " 12 \n",
    " 13 \n",
    " 14 \n",
    " 15 §E\n",
    " 16 \n",
    " 17 Imam ...m.\n",
    " 18 ............g. pu...g...y\n",
    " 19 13.5.... u..».s._y_:\n",
    " 20 :.aa:»0In.n-an mm\n",
    " 21 A.¢¢1.~...u [sunsc-/.1\n",
    " 22 \n",
    "\n",
    "This is typical for most files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, it's kind of disappointing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
